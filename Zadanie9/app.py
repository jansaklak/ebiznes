import streamlit as st
import requests
import json
from typing import Optional
import time

st.set_page_config(
    page_title="Google Gemini Client",
    page_icon="ğŸ¤–",
    layout="wide"
)

BACKEND_URL = "http://localhost:8000"

class GeminiClient:
    def __init__(self, backend_url: str):
        self.backend_url = backend_url
    
    def check_backend_health(self) -> bool:
        """Sprawdza czy backend jest dostÄ™pny"""
        try:
            response = requests.get(f"{self.backend_url}/health", timeout=5)
            return response.status_code == 200
        except requests.exceptions.RequestException:
            return False
    
    def send_message(self, message: str, model: str = "gemini-1.5-flash", 
                    max_tokens: int = 1000, temperature: float = 0.7) -> dict:
        """WysyÅ‚a wiadomoÅ›Ä‡ do Google Gemini przez backend"""
        try:
            payload = {
                "message": message,
                "model": model,
                "max_tokens": max_tokens,
                "temperature": temperature
            }
            
            response = requests.post(
                f"{self.backend_url}/chat",
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                return {"success": True, "data": response.json()}
            else:
                error_detail = response.json().get("detail", "Nieznany bÅ‚Ä…d")
                return {"success": False, "error": error_detail}
                
        except requests.exceptions.Timeout:
            return {"success": False, "error": "Timeout - serwer nie odpowiada"}
        except requests.exceptions.ConnectionError:
            return {"success": False, "error": "BÅ‚Ä…d poÅ‚Ä…czenia z backendem"}
        except Exception as e:
            return {"success": False, "error": f"Nieoczekiwany bÅ‚Ä…d: {str(e)}"}
    
    def analyze_text(self, message: str, model: str = "gemini-1.5-flash",
                    max_tokens: int = 1000, temperature: float = 0.7) -> dict:
        """Analizuje tekst przed wysÅ‚aniem do Google Gemini"""
        try:
            payload = {
                "message": message,
                "model": model,
                "max_tokens": max_tokens,
                "temperature": temperature
            }
            
            response = requests.post(
                f"{self.backend_url}/analyze-text",
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                return {"success": True, "data": response.json()}
            else:
                error_detail = response.json().get("detail", "Nieznany bÅ‚Ä…d")
                return {"success": False, "error": error_detail}
                
        except Exception as e:
            return {"success": False, "error": f"BÅ‚Ä…d analizy: {str(e)}"}

# Client initialization
@st.cache_resource
def get_client():
    return GeminiClient(BACKEND_URL)

def main():
    st.title("ğŸ¤– Google Gemini Client")
    st.markdown("---")
    
    client = get_client()
    
    # Check backend status and configuration
    with st.sidebar:
        st.header("âš™ï¸ Konfiguracja")
        
        # Backend status
        if client.check_backend_health():
            st.success("âœ… Backend poÅ‚Ä…czony")
        else:
            st.error("âŒ Backend niedostÄ™pny")
            st.warning("Uruchom backend: `uvicorn main:app --reload`")
        
        st.markdown("---")
        
        model = st.selectbox(
            "Model Gemini:",
            ["gemini-1.5-flash", "gemini-1.5-pro", "gemini-pro"],
            index=0
        )
        
        max_tokens = st.slider(
            "Maksymalna liczba tokenÃ³w:",
            min_value=100,
            max_value=2000,
            value=1000,
            step=100
        )
        
        temperature = st.slider(
            "Temperatura (kreatywnoÅ›Ä‡):",
            min_value=0.0,
            max_value=2.0,
            value=0.7,
            step=0.1
        )
        
        st.markdown("---")
        
        # Tryb pracy
        mode = st.radio(
            "Tryb pracy:",
            ["ZwykÅ‚y chat", "Analiza tekstu"],
            index=0
        )
    
    # Main interface
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ’¬ Chat")
        
        user_message = st.text_area(
            "Wpisz swojÄ… wiadomoÅ›Ä‡:",
            height=150,
            placeholder="Napisz tutaj swojÄ… wiadomoÅ›Ä‡ do Google Gemini..."
        )
        
        send_button = st.button("ğŸ“¤ WyÅ›lij", type="primary")
        
        if send_button and user_message.strip():
            if not client.check_backend_health():
                st.error("Backend jest niedostÄ™pny. SprawdÅº czy serwis dziaÅ‚a.")
                return
            
            with st.spinner("WysyÅ‚am zapytanie do Google Gemini..."):
                if mode == "ZwykÅ‚y chat":
                    result = client.send_message(
                        user_message, model, max_tokens, temperature
                    )
                else:
                    result = client.analyze_text(
                        user_message, model, max_tokens, temperature
                    )
                
                if result["success"]:
                    data = result["data"]
                    
                    st.success("âœ… Otrzymano odpowiedÅº!")
                    
                    st.markdown("### ğŸ¤– OdpowiedÅº Google Gemini:")
                    st.markdown(data["response"])
                    
                    with st.expander("â„¹ï¸ SzczegÃ³Å‚y zapytania"):
                        st.write(f"**Model:** {data['model_used']}")
                        if data.get('tokens_used'):
                            st.write(f"**UÅ¼yte tokeny:** {data['tokens_used']}")
                        st.write(f"**Tryb:** {mode}")
                else:
                    st.error(f"âŒ BÅ‚Ä…d: {result['error']}")
        
        elif send_button and not user_message.strip():
            st.warning("âš ï¸ ProszÄ™ wpisaÄ‡ wiadomoÅ›Ä‡ przed wysÅ‚aniem!")
    
    with col2:
        st.header("ğŸ“Š Historia")
        
        if "chat_history" not in st.session_state:
            st.session_state.chat_history = []
        
        if send_button and user_message.strip() and client.check_backend_health():
            if mode == "ZwykÅ‚y chat":
                result = client.send_message(user_message, model, max_tokens, temperature)
            else:
                result = client.analyze_text(user_message, model, max_tokens, temperature)
                
            if result["success"]:
                st.session_state.chat_history.append({
                    "timestamp": time.strftime("%H:%M:%S"),
                    "user_message": user_message[:50] + "..." if len(user_message) > 50 else user_message,
                    "response": result["data"]["response"][:100] + "..." if len(result["data"]["response"]) > 100 else result["data"]["response"],
                    "mode": mode
                })
        
        if st.session_state.chat_history:
            for i, chat in enumerate(reversed(st.session_state.chat_history[-5:])):  # Ostatnie 5
                with st.expander(f"{chat['timestamp']} - {chat['mode']}"):
                    st.write(f"**Ty:** {chat['user_message']}")
                    st.write(f"**Gemini:** {chat['response']}")
        else:
            st.info("Historia chat-Ã³w pojawi siÄ™ tutaj")
        
        if st.button("ğŸ—‘ï¸ WyczyÅ›Ä‡ historiÄ™"):
            st.session_state.chat_history = []
            st.rerun()
    
    # Stopka
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center'>
            <small>
                ğŸ”§ Backend: FastAPI | ğŸ–¥ï¸ Frontend: Streamlit | ğŸ¤– AI: Google Gemini
            </small>
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()